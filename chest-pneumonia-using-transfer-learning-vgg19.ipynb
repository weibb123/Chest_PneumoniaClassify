{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport glob # to find files\n\n\nimport seaborn as sns\n\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, layers\n\n# import VGG19 to perform transfer learning\nfrom tensorflow.keras.applications import VGG19\nfrom keras.applications.vgg19 import preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-12T22:27:56.255780Z","iopub.execute_input":"2021-10-12T22:27:56.256128Z","iopub.status.idle":"2021-10-12T22:28:01.502108Z","shell.execute_reply.started":"2021-10-12T22:27:56.256100Z","shell.execute_reply":"2021-10-12T22:28:01.501239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Creating Dataset:\n<br> We want to grab jpg files from folder and create a dataset </br>\n<br> training_folder : containing all training chest images of normal/pneumonia </br>\n<br> testing_folder : containing all testing chest images of normal/pneumonia </br>\n<br> validation_folder : containing all validation chest images of normal/pneumonia for purpose of validation </br>","metadata":{}},{"cell_type":"code","source":"path = '../input/chest-xray-pneumonia/chest_xray/'\n\n# train directory\ntrain_folder=path+\"train/\"\ntrain_normal_dir=train_folder+\"NORMAL/\"\ntrain_pneu_dir=train_folder+\"PNEUMONIA/\"\n\n# test directory\ntest_folder=path+\"test/\"\ntest_normal_dir=test_folder+\"NORMAL/\"\ntest_pneu_dir=test_folder+\"PNEUMONIA/\"\n\n# validation directory\nval_folder=path+\"val/\"\nval_normal_dir=val_folder+\"NORMAL/\"\nval_pneu_dir=val_folder+\"PNEUMONIA/\"\n\n# variables for image size (VGG19 uses 224,224 as input, we should change size of image to 224)\nimg_width=224\nimg_height=224\n\n# variable for model\nbatch_size=64\nepochs=10","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.504452Z","iopub.execute_input":"2021-10-12T22:28:01.504720Z","iopub.status.idle":"2021-10-12T22:28:01.513893Z","shell.execute_reply.started":"2021-10-12T22:28:01.504695Z","shell.execute_reply":"2021-10-12T22:28:01.513006Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Create list of classes","metadata":{}},{"cell_type":"code","source":"# Train Dataset\ntrain_class_names=os.listdir(train_folder)\nprint(\"Train class names: %s\" % (train_class_names))\n# print(\"\\n\")\n\n# Test Dataset\ntest_class_names=os.listdir(test_folder)\nprint(\"Test class names: %s\" % (test_class_names))\n# print(\"\\n\")\n\n# Validation Dataset\nval_class_names=os.listdir(val_folder)\nprint(\"Validation class names: %s\" % (val_class_names))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.516386Z","iopub.execute_input":"2021-10-12T22:28:01.516651Z","iopub.status.idle":"2021-10-12T22:28:01.532648Z","shell.execute_reply.started":"2021-10-12T22:28:01.516628Z","shell.execute_reply":"2021-10-12T22:28:01.531876Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Find all jpeg and put in list ","metadata":{}},{"cell_type":"code","source":"# find all files, our files has extension jpeg\ntrain_normal_cases = glob.glob(train_normal_dir + '*jpeg')\ntrain_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')\n\ntest_normal_cases = glob.glob(test_normal_dir + '*jpeg')\ntest_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')\n\nval_normal_cases = glob.glob(val_normal_dir + '*jpeg')\nval_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')\n\n# create lists for train, test & validation cases, create labels as well\ntrain_list = []\ntest_list = []\nval_list = []\n\nfor x in train_normal_cases:\n    train_list.append([x, \"Normal\"])\n    \nfor x in train_pneu_cases:\n    train_list.append([x, \"Pneumonia\"])\n    \nfor x in test_normal_cases:\n    test_list.append([x, \"Normal\"])\n    \nfor x in test_pneu_cases:\n    test_list.append([x, \"Pneumonia\"])\n    \nfor x in val_normal_cases:\n    val_list.append([x, \"Normal\"])\n    \nfor x in val_pneu_cases:\n    val_list.append([x, \"Pneumonia\"])\n\n# create dataframes for training, test, valid\ntrain_df = pd.DataFrame(train_list, columns=['image', 'Diagnos'])\nprint(train_df.shape)\ntest_df = pd.DataFrame(test_list, columns=['image', 'Diagnos'])\nprint(test_df.shape)\nval_df = pd.DataFrame(val_list, columns=['image', 'Diagnos'])\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.535590Z","iopub.execute_input":"2021-10-12T22:28:01.535838Z","iopub.status.idle":"2021-10-12T22:28:01.662308Z","shell.execute_reply.started":"2021-10-12T22:28:01.535814Z","shell.execute_reply":"2021-10-12T22:28:01.661572Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.sample(frac=1).reset_index(drop=True)\nprint(train_df)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.664793Z","iopub.execute_input":"2021-10-12T22:28:01.665042Z","iopub.status.idle":"2021-10-12T22:28:01.683152Z","shell.execute_reply.started":"2021-10-12T22:28:01.665018Z","shell.execute_reply":"2021-10-12T22:28:01.682250Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df['Diagnos'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.684413Z","iopub.execute_input":"2021-10-12T22:28:01.684765Z","iopub.status.idle":"2021-10-12T22:28:01.696611Z","shell.execute_reply.started":"2021-10-12T22:28:01.684730Z","shell.execute_reply":"2021-10-12T22:28:01.695621Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Because our dataset has imbalance number of Normal/Pneumonia training examples, our model might tend to predict Penumonia images more accurately","metadata":{}},{"cell_type":"markdown","source":"# Change jpeg to array \nChange jpeg into array so we can use numpy / tensorflow on them. or plot them.","metadata":{}},{"cell_type":"code","source":"# Declaring variables\nx=[] # to store array value of the images\ny=[] # to store the labels of the images\n\nfor folder in os.listdir(train_folder):\n    image_list=os.listdir(train_folder+\"/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(train_folder+\"/\"+folder+\"/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrary\n        img=image.img_to_array(img)\n        \n        # Transfer Learning: this is to apply preprocess of VGG19 model to our images before passing it to VGG19\n        img=preprocess_input(img) # Required since we using transfer-learning \n        \n        # Appending the arrarys\n        x.append(img) # appending image array\n        y.append(train_class_names.index(folder)) # appending class index to the array\n        \nprint(\"Training Dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:28:01.698242Z","iopub.execute_input":"2021-10-12T22:28:01.699091Z","iopub.status.idle":"2021-10-12T22:29:34.589646Z","shell.execute_reply.started":"2021-10-12T22:28:01.699053Z","shell.execute_reply":"2021-10-12T22:29:34.588671Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def showimg(x, y):\n    plt.figure(figsize=(10,10))\n    \n    # Plotting 25 images\n    for n in range(25):\n        \n        \n        ax = plt.subplot(5,5,n+1)\n       \n        plt.imshow(x[n])\n        if y[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")\n\nshowimg(x,y)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:34.590980Z","iopub.execute_input":"2021-10-12T22:29:34.591500Z","iopub.status.idle":"2021-10-12T22:29:35.976117Z","shell.execute_reply.started":"2021-10-12T22:29:34.591460Z","shell.execute_reply":"2021-10-12T22:29:35.975230Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Declaring variables\nval_images=[]\nval_images_Original=[]\nval_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(val_folder):\n    image_list=os.listdir(val_folder+\"/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(val_folder+\"/\"+folder+\"/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        val_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG19 to our images before passing it to VGG19\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending arrays\n        val_images.append(img) # appending image array\n        val_image_label.append(val_class_names.index(folder))\n        \nprint(\"Validation Dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:35.978869Z","iopub.execute_input":"2021-10-12T22:29:35.979186Z","iopub.status.idle":"2021-10-12T22:29:36.257974Z","shell.execute_reply.started":"2021-10-12T22:29:35.979153Z","shell.execute_reply":"2021-10-12T22:29:36.256904Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Declaring variables\ntest_images=[]\ntest_images_Original=[]\ntest_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(test_folder):\n    image_list=os.listdir(test_folder+\"/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(test_folder+\"/\"+folder+\"/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        test_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG19 to our images \n        img=preprocess_input(img) \n        \n        # Appending arrays\n        test_images.append(img) # appending image array\n        test_image_label.append(test_class_names.index(folder))\n        \nprint(\"Test Dataset\")","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:36.259871Z","iopub.execute_input":"2021-10-12T22:29:36.260423Z","iopub.status.idle":"2021-10-12T22:29:44.456132Z","shell.execute_reply.started":"2021-10-12T22:29:36.260381Z","shell.execute_reply":"2021-10-12T22:29:44.454529Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Training Dataset\nprint(\"Training Dataset:\")\n\nx=np.array(x) # Converting to np arrary to pass to the model\nprint(x.shape)\n\ny=to_categorical(y) # onehot encoding of the labels (Sparse Matrix)\n# print(y)\nprint(y.shape)\n\n# ===========\n\n# Test Dataset\nprint(\"Test Dataset:\")\n\ntest_images=np.array(test_images) \nprint(test_images.shape)\n\ntest_image_label=to_categorical(test_image_label) # onehot encoding of the labels)\nprint(test_image_label.shape)\n\n# ===========\n\n# Validation Dataset\nprint(\"Validation Dataset:\")\n\nval_images=np.array(val_images) \nprint(val_images.shape)\n\nval_image_label=to_categorical(val_image_label) # onehot encoding of the labels)\nprint(val_image_label.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:44.457541Z","iopub.execute_input":"2021-10-12T22:29:44.457908Z","iopub.status.idle":"2021-10-12T22:29:46.698184Z","shell.execute_reply.started":"2021-10-12T22:29:44.457869Z","shell.execute_reply":"2021-10-12T22:29:46.697294Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(y)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:46.699516Z","iopub.execute_input":"2021-10-12T22:29:46.699880Z","iopub.status.idle":"2021-10-12T22:29:46.705162Z","shell.execute_reply.started":"2021-10-12T22:29:46.699843Z","shell.execute_reply":"2021-10-12T22:29:46.704286Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Deep Learning Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\nmodel = VGG19(weights='imagenet')\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:46.706400Z","iopub.execute_input":"2021-10-12T22:29:46.706985Z","iopub.status.idle":"2021-10-12T22:29:50.486128Z","shell.execute_reply.started":"2021-10-12T22:29:46.706938Z","shell.execute_reply":"2021-10-12T22:29:50.485271Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Input Image to VGG19 must be (224, 224, 3) where 3 represents color channel","metadata":{}},{"cell_type":"code","source":"input_layer=layers.Input(shape=(img_width, img_height, 3)) \nmodel=VGG19(weights='imagenet',input_tensor=input_layer,include_top=False)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:50.490450Z","iopub.execute_input":"2021-10-12T22:29:50.490929Z","iopub.status.idle":"2021-10-12T22:29:50.969409Z","shell.execute_reply.started":"2021-10-12T22:29:50.490887Z","shell.execute_reply":"2021-10-12T22:29:50.968427Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"We flatten the last layer and change output to 2 nodes for softmax function because we have 2 outcomes, <br> Normal chest / Not Normal chest </br>","metadata":{}},{"cell_type":"code","source":"last_layer=model.output\nflatten= layers.Flatten()(last_layer)\noutput_layer=layers.Dense(2,activation='softmax')(flatten)\nmodel=models.Model(inputs=input_layer,outputs=output_layer)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:50.972473Z","iopub.execute_input":"2021-10-12T22:29:50.972764Z","iopub.status.idle":"2021-10-12T22:29:51.006360Z","shell.execute_reply.started":"2021-10-12T22:29:50.972723Z","shell.execute_reply":"2021-10-12T22:29:51.005250Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(\"We are making all the layers intrainable except the last layer. \\n\")\nfor layer in model.layers[:-1]:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:51.007794Z","iopub.execute_input":"2021-10-12T22:29:51.008135Z","iopub.status.idle":"2021-10-12T22:29:51.016439Z","shell.execute_reply.started":"2021-10-12T22:29:51.008100Z","shell.execute_reply":"2021-10-12T22:29:51.015472Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### 80% training data, 20% testing data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=5)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:51.018355Z","iopub.execute_input":"2021-10-12T22:29:51.018865Z","iopub.status.idle":"2021-10-12T22:29:51.997940Z","shell.execute_reply.started":"2021-10-12T22:29:51.018715Z","shell.execute_reply":"2021-10-12T22:29:51.996968Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Must use Categorical_crossentropy because we have 2 outputs and we use one-hot encoding on our y-values","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:51.999361Z","iopub.execute_input":"2021-10-12T22:29:51.999754Z","iopub.status.idle":"2021-10-12T22:29:52.016258Z","shell.execute_reply.started":"2021-10-12T22:29:51.999715Z","shell.execute_reply":"2021-10-12T22:29:52.015326Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"history=model.fit(xtrain,ytrain,epochs=10,batch_size=batch_size,verbose=True,validation_data=(xtest,ytest))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:29:52.017581Z","iopub.execute_input":"2021-10-12T22:29:52.018302Z","iopub.status.idle":"2021-10-12T22:32:12.811431Z","shell.execute_reply.started":"2021-10-12T22:29:52.018264Z","shell.execute_reply":"2021-10-12T22:32:12.809468Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy  = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:32:12.814199Z","iopub.execute_input":"2021-10-12T22:32:12.814594Z","iopub.status.idle":"2021-10-12T22:32:12.820327Z","shell.execute_reply.started":"2021-10-12T22:32:12.814557Z","shell.execute_reply":"2021-10-12T22:32:12.819394Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.ylim(0.8, 1)\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.ylim(0, 0.5)\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:32:12.821838Z","iopub.execute_input":"2021-10-12T22:32:12.822231Z","iopub.status.idle":"2021-10-12T22:32:13.144540Z","shell.execute_reply.started":"2021-10-12T22:32:12.822201Z","shell.execute_reply":"2021-10-12T22:32:13.143471Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ndef Get_Xray_Type(argument):\n    switcher = {\n        \"NORMAL\": \"Normal\",\n        \"PNEUMONIA\": \"Pneumonia\",\n    }\n    return switcher.get(argument, \"Invalid X-ray\")\ndef predict(img_name):\n    img=image.load_img(img_name,target_size=(img_width,img_height))\n    img=image.img_to_array(img)\n    plt.imshow(img.astype('int32'))\n    plt.show()\n    img=preprocess_input(img)\n#     plt.imshow(img.astype('int32'))\n#     plt.show()\n    prediction=model.predict(img.reshape(1,img_width,img_height,3))\n    output=np.argmax(prediction)\n    print(train_class_names[output] + \": \" + Get_Xray_Type(train_class_names[output]))\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-10-12T22:32:13.146049Z","iopub.execute_input":"2021-10-12T22:32:13.146422Z","iopub.status.idle":"2021-10-12T22:32:13.153270Z","shell.execute_reply.started":"2021-10-12T22:32:13.146383Z","shell.execute_reply":"2021-10-12T22:32:13.152142Z"},"trusted":true},"execution_count":23,"outputs":[]}]}